{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quant Equity Alpha Platform - Quickstart\n",
    "\n",
    "This notebook demonstrates the end-to-end workflow:\n",
    "1. Data ingestion from EODHD\n",
    "2. Feature engineering\n",
    "3. Model training with walk-forward CV\n",
    "4. Portfolio optimization\n",
    "5. Backtesting with realistic costs\n",
    "6. Report generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from src.eodhd_client import EODHDClient\n",
    "from src.pit_store import PITDataStore\n",
    "from src.features.factors import FactorEngine, compute_forward_returns\n",
    "from src.models.train import train_with_cv\n",
    "from src.portfolio.optimizer import PortfolioOptimizer, PortfolioConstraints\n",
    "from src.backtest.runner import Backtester, compute_backtest_summary\n",
    "from src.backtest.costs import TransactionCostModel\n",
    "from src.utils.clock import TradingCalendar, get_rebalance_dates\n",
    "from src.reporting.report import ReportGenerator\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "with open('../config/defaults.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Quick test configuration\n",
    "config['start_date'] = '2022-01-01'\n",
    "config['end_date'] = '2023-12-31'\n",
    "config['universe']['max_tickers'] = 50  # Limit for quick demo\n",
    "\n",
    "print(f\"Date range: {config['start_date']} to {config['end_date']}\")\n",
    "print(f\"Max tickers: {config['universe']['max_tickers']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Ingestion (Simplified)\n",
    "\n",
    "For this demo, we'll create synthetic data. In production, use scripts/ingest.py to fetch real EODHD data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic data for demo\n",
    "np.random.seed(42)\n",
    "\n",
    "tickers = [f\"TICK{i:02d}\" for i in range(50)]\n",
    "dates = pd.date_range(config['start_date'], config['end_date'], freq='D')\n",
    "\n",
    "# Generate synthetic prices\n",
    "price_data = []\n",
    "for ticker in tickers:\n",
    "    base_price = np.random.uniform(50, 200)\n",
    "    returns = np.random.randn(len(dates)) * 0.02  # 2% daily vol\n",
    "    prices = base_price * np.exp(returns.cumsum())\n",
    "    \n",
    "    for date, price in zip(dates, prices):\n",
    "        price_data.append({\n",
    "            'date': date,\n",
    "            'ticker': ticker,\n",
    "            'close': price,\n",
    "            'adj_close': price,\n",
    "            'volume': np.random.uniform(1e6, 10e6),\n",
    "            'sector': np.random.choice(['Tech', 'Finance', 'Healthcare']),\n",
    "        })\n",
    "\n",
    "prices_df = pd.DataFrame(price_data)\n",
    "\n",
    "# Generate synthetic fundamentals\n",
    "fundamentals_data = []\n",
    "for ticker in tickers:\n",
    "    for quarter in pd.date_range(config['start_date'], config['end_date'], freq='Q'):\n",
    "        fundamentals_data.append({\n",
    "            'ticker': ticker,\n",
    "            'filing_date': quarter,\n",
    "            'shares_outstanding': np.random.uniform(1e9, 10e9),\n",
    "            'net_income_ttm': np.random.uniform(1e9, 10e9),\n",
    "            'fcf_ttm': np.random.uniform(0.5e9, 8e9),\n",
    "            'ebitda_ttm': np.random.uniform(2e9, 15e9),\n",
    "            'total_assets': np.random.uniform(10e9, 100e9),\n",
    "            'total_liabilities': np.random.uniform(5e9, 80e9),\n",
    "        })\n",
    "\n",
    "fundamentals_df = pd.DataFrame(fundamentals_data)\n",
    "\n",
    "print(f\"Generated {len(prices_df)} price records\")\n",
    "print(f\"Generated {len(fundamentals_df)} fundamental records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store in PIT store\n",
    "pit_store = PITDataStore(\n",
    "    data_dir='../data/demo',\n",
    "    pit_lag_days=config['pit_lag_days']\n",
    ")\n",
    "\n",
    "pit_store.store_prices(prices_df)\n",
    "pit_store.store_fundamentals(fundamentals_df)\n",
    "\n",
    "print(\"✓ Data stored in PIT store\")\n",
    "\n",
    "# Validate PIT integrity\n",
    "validation = pit_store.validate_pit_integrity()\n",
    "print(f\"PIT validation: {'PASSED' if validation['passed'] else 'FAILED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pit_store.merge_prices_fundamentals(\n",
    "    start_date=config['start_date'],\n",
    "    end_date=config['end_date']\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(df)} rows for {df['ticker'].nunique()} tickers\")\n",
    "\n",
    "# Compute factors\n",
    "factor_engine = FactorEngine(\n",
    "    winsorize_quantiles=tuple(config['features']['winsorize_quantiles']),\n",
    "    min_sector_size=5  # Relaxed for demo\n",
    ")\n",
    "\n",
    "factor_dfs = []\n",
    "for date, date_df in df.groupby('date'):\n",
    "    date_df = factor_engine.compute_all_factors(date_df, compute_composite=True)\n",
    "    factor_dfs.append(date_df)\n",
    "\n",
    "df = pd.concat(factor_dfs, ignore_index=True)\n",
    "\n",
    "# Compute forward returns\n",
    "df = compute_forward_returns(df, horizon_days=21)\n",
    "\n",
    "print(f\"✓ Features computed\")\n",
    "print(f\"Available features: {[col for col in df.columns if col.endswith('_z')]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to samples with valid target\n",
    "target_col = 'next_21d_excess_vs_sector'\n",
    "train_df = df[df[target_col].notna()].copy()\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "\n",
    "# Get feature columns\n",
    "feature_cols = factor_engine.get_feature_columns(standardized=True)\n",
    "feature_cols = [col for col in feature_cols if col in train_df.columns]\n",
    "\n",
    "print(f\"Using {len(feature_cols)} features\")\n",
    "\n",
    "# Train with walk-forward CV\n",
    "model, cv_results = train_with_cv(\n",
    "    df=train_df,\n",
    "    model_config=config['model'],\n",
    "    cv_config=config['cv'],\n",
    "    feature_cols=feature_cols,\n",
    "    target_col=target_col,\n",
    "    date_col='date'\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Model trained\")\n",
    "print(f\"Mean Test IC: {cv_results['test_ic'].mean():.4f}\")\n",
    "print(f\"Mean Rank IC: {cv_results['test_rank_ic'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CV results\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(cv_results['fold'], cv_results['test_ic'], marker='o', label='Test IC')\n",
    "plt.axhline(cv_results['test_ic'].mean(), color='r', linestyle='--', label=f\"Mean: {cv_results['test_ic'].mean():.4f}\")\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('IC')\n",
    "plt.title('Information Coefficient by Fold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for all dates\n",
    "df['alpha_score'] = model.predict(df)\n",
    "\n",
    "print(f\"✓ Predictions generated\")\n",
    "print(f\"Score range: [{df['alpha_score'].min():.4f}, {df['alpha_score'].max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Portfolio Optimization & Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup calendar and rebalance dates\n",
    "calendar = TradingCalendar(\n",
    "    config['start_date'],\n",
    "    config['end_date'],\n",
    "    exchange='US'\n",
    ")\n",
    "\n",
    "rebalance_dates = get_rebalance_dates(\n",
    "    config['start_date'],\n",
    "    config['end_date'],\n",
    "    frequency='weekly',\n",
    "    calendar=calendar\n",
    ")\n",
    "\n",
    "print(f\"Rebalance dates: {len(rebalance_dates)}\")\n",
    "\n",
    "# Setup portfolio optimizer\n",
    "constraints = PortfolioConstraints(\n",
    "    long_pct=config['portfolio']['long_pct'],\n",
    "    short_pct=config['portfolio']['short_pct'],\n",
    "    sector_max_weight=config['portfolio']['sector_max_weight'],\n",
    "    single_name_max_weight=config['portfolio']['single_name_max_weight'],\n",
    "    gross_leverage=config['portfolio']['gross_leverage'],\n",
    "    turnover_penalty=config['optimizer']['turnover_penalty'],\n",
    ")\n",
    "\n",
    "optimizer = PortfolioOptimizer(constraints, use_pca_risk=False)\n",
    "\n",
    "# Weight function\n",
    "prev_weights = None\n",
    "\n",
    "def get_weights(date):\n",
    "    global prev_weights\n",
    "    date_df = df[df['date'] == date].copy()\n",
    "    if date_df.empty:\n",
    "        return pd.Series(dtype=float)\n",
    "    \n",
    "    date_df = date_df.set_index('ticker')\n",
    "    weights = optimizer.optimize(\n",
    "        scores=date_df['alpha_score'],\n",
    "        sectors=date_df['sector'],\n",
    "        prices=date_df['adj_close'],\n",
    "        prev_weights=prev_weights\n",
    "    )\n",
    "    prev_weights = weights.copy()\n",
    "    return weights\n",
    "\n",
    "# Setup backtester\n",
    "cost_model = TransactionCostModel(\n",
    "    bps_per_side=config['costs']['bps_per_side'],\n",
    "    spread_proxy_bps=config['costs']['spread_proxy_bps']\n",
    ")\n",
    "\n",
    "backtester = Backtester(\n",
    "    initial_capital=1_000_000,\n",
    "    cost_model=cost_model,\n",
    "    calendar=calendar\n",
    ")\n",
    "\n",
    "# Run backtest\n",
    "print(\"Running backtest...\")\n",
    "price_data = df[['date', 'ticker', 'adj_close', 'volume']].copy()\n",
    "\n",
    "result = backtester.run(\n",
    "    rebalance_dates=rebalance_dates[:20],  # Limit for demo\n",
    "    weight_func=get_weights,\n",
    "    price_data=price_data,\n",
    "    execution_lag=1\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Backtest complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary\n",
    "summary = compute_backtest_summary(result)\n",
    "print(summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot equity curve\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# Portfolio value\n",
    "ax1.plot(result.portfolio_values.index, result.portfolio_values.values, linewidth=2)\n",
    "ax1.set_title('Portfolio Value', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Value ($)', fontsize=12)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Cumulative returns\n",
    "cum_returns = (1 + result.returns).cumprod()\n",
    "ax2.plot(cum_returns.index, cum_returns.values, linewidth=2, color='green')\n",
    "ax2.set_title('Cumulative Returns', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('Cumulative Return', fontsize=12)\n",
    "ax2.set_xlabel('Date', fontsize=12)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate Full Report\n",
    "\n",
    "For production use, run: `python scripts/report.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"QUICKSTART COMPLETE\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nFinal Portfolio Value: ${result.portfolio_values.iloc[-1]:,.0f}\")\n",
    "print(f\"Total Return: {result.metrics['total_return']*100:.2f}%\")\n",
    "print(f\"Sharpe Ratio: {result.metrics['sharpe']:.2f}\")\n",
    "print(f\"\\nNext steps:\")\n",
    "print(\"1. Use scripts/ingest.py for real EODHD data\")\n",
    "print(\"2. Customize config/defaults.yaml\")\n",
    "print(\"3. Run full pipeline with scripts/train.py and scripts/backtest.py\")\n",
    "print(\"4. Generate comprehensive report with scripts/report.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
